I"’<blockquote>
  <p>Project currently underway</p>
</blockquote>

<h2 id="overview">Overview</h2>

<p>Sighted users have access to a screenâ€™s worth of information when interacting with computers and mobile devices. Visually Challenged users access the same information primarily via screen readers and physical braille displays, while users with low vision can make use of visual content by means of screen magnifiers. Screen readers present information in the form of synthesized speech sequentially and upon command.</p>

<p>In its simplest form, this project explores the following question:</p>

<p><strong><em>What if visually challenged users were presented with more auditory information to access at a time?</em></strong></p>

<p><img src="\media\thumbnails\P2thumbnail.png" alt="VR1" /></p>

<p><br /></p>

<p>Over the course of the project, these questions have become a lot more defined, and have grounded themselves in real problems and past studies in the area.</p>

<p>In parallel, I have been motivated by the idea that this project, and the basic research that it attempts, might eventually help in the design of more ambitious auditory interfaces. Perhaps of the kind where information is sonified all around us, and can be accessed by turning our heads or pointing a finger, as naturally as we might glance over a screen or display today.</p>

<p><br /></p>

<h3 id="abstract">Abstract</h3>

<p>Most information on the internet is predominantly visual in nature, or is meant to be accessed using graphical interfaces. Visually challenged users access this information through assistive technologies such as screen readers. However, unlike sighted users who have a wealth of visual information available on device screens, visually challenged users only have access to a single stream of auditory information through these screen readers. Recent studies in the field of assistive technologies for Visually Challenged persons have discussed the introduction of Concurrent Speech as a potential feature in screen readers and voice interfaces. Before designing for Concurrent Speech, there needs to be a thorough analysis of the design variables that would influence such interfaces. In this study, We focus on 2 fundamental variables, namely the number of concurrent speakers, and the differentiation of voice characteristics, and compare user performance and preference across 5 resultant configurations - 1 Speaker, 2 Speakers with Same Voices, 2 Speakers with Different Voices, 3 Speakers with Same Voices, and 3 Speakers with Different Voices. We aim to conduct 2 within-subjects studies with visually challenged users and sighted users. Participants will be asked to perform list scanning and searching tasks. We will assess task duration,errors and preference for each of the 5 configurations.</p>

<p><br /></p>

<h3 id="about">About</h3>

<p>A short presentation on the project:</p>

<iframe class="video" src="https://docs.google.com/presentation/d/e/2PACX-1vQVyU6XQ-nS8f6r9dfhaLwpU--GSYCXl0DNdDvtLB79KKwmVqZ_JCDji3QVCVH6zTIv9o0rhkUffKhZ/embed?start=false&amp;loop=true&amp;delayms=60000" frameborder="0" allowfullscreen="true" mozallowfullscreen="true" webkitallowfullscreen="true"></iframe>

:ET